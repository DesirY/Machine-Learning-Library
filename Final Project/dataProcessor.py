'''
1. complete the missing data
2. convert the continous feature into discrete feature
3. one-hot encondes the discrete feature generated by the continous feature
4. one-hot encode all discrete feature
'''

import csv
import numpy as np
from numpy import fabs, random
from numpy.lib.function_base import percentile, sort_complex
from numpy.lib.shape_base import split
import pandas as pd

from BoostingTrees import process_training_data



MISSING_DATA = ['?']
CONTINUOUS_ATTR = ['fnlwgt']
INTEGER_ATTR = ['age', 'education.num', 'hours.per.week', 'capital.gain', 'capital.loss']

class dProcessor():
    def __init__(self, training_data, test_data):
        self.training_data = training_data
        self.test_data = test_data
        # the length of the training data
        self.num = training_data.shape[0]
        # handle the missing data
        # self.missing_data_handler(self.training_data)
        self.missing_data_handler(self.test_data)
        # discrete the continuous feature
        self.discrete_rules = self.get_discrete_rules(self.training_data) # get the discrete rule
        # print(self.discrete_rules)
        self.discrete_to_continuous(self.training_data)
        self.discrete_to_continuous(self.test_data)

        self.write_into_file(self.training_data, 'training_data_full')
        self.write_into_file(self.test_data, 'test_data_full')
        
    
    # process the missing data of the data
    # mode, median and average
    def missing_data_handler(self, data):
        for col in data.columns:
            # print(col)
            rpl = ''
            if col in CONTINUOUS_ATTR:
                # average
                rpl = data[col].mean()
                data[col].fillna(rpl, inplace=True)
            elif col in INTEGER_ATTR:
                # median
                rpl = data[col].median()
                data[col].fillna(rpl, inplace=True)
            else:
                # mode
                rpl = data[col].mode()
                data[col].fillna(rpl[0], inplace=True)    # must rpl[0]


    # write the data into csv file 
    def write_into_file(self, data, name):
        data.to_csv('./Processed_Data/'+name+'.csv')

    # get the discrete rules
    def get_discrete_rules(self, data):
        con_attr = CONTINUOUS_ATTR + INTEGER_ATTR
        res_dict = {}

        for attr in con_attr:
            split_num = 0   # the number of split
            
            if attr == 'age':
                split_num = 12
            elif attr == 'fnlwgt':
                split_num = 6
            elif attr == 'education.num':
                split_num = 6
            elif attr == 'capital.gain':
                split_num = 3
            elif attr == 'capital.loss':
                split_num = 3
            elif attr == 'hours.per.week':
                split_num = 6
            
            w = [1.0 * i / split_num for i in range(split_num+1)]
            w = data[attr].describe(percentiles=w)[4:4+split_num+1]
            w[0] -= 1e-10

            res_dict[attr] = w
    
        return res_dict

                   
    def get_quantile_range(self, gap_num):
        gap = 1/gap_num
        return np.arange(0, gap*(gap_num+1), gap)


    # transform the data from continous to discrete ones
    def discrete_to_continuous(self, data):
        con_attrs = CONTINUOUS_ATTR+INTEGER_ATTR

        for attr in con_attrs:
            data[attr] = pd.cut(data[attr], self.discrete_rules[attr], duplicates='drop', labels=False)
            for index, value in data[attr].items():
                data.loc[index, attr] = attr + '_' + str(data.loc[index, attr])


if __name__ == '__main__':
    training_data = pd.read_csv('./Data/train_final_full.csv', na_values=MISSING_DATA)
    test_data = pd.read_csv('./Data/test_final.csv', na_values=MISSING_DATA)
    processor = dProcessor(training_data, test_data)
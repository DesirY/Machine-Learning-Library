
This is a machine learning library developed by **Xinyuan Yan** for CS5350/6350 in University of Utah

**Decision Tree**
***
* *ID3Alg_2a.py*, *ID3Alg_3a.py*, and *ID3Alg_3b.py* are corrsponded with *2(a)*,*3(a)*, *3(b)* in **Homework 1 Part 2** respectively.You can use run_2a.sh, run_3a.sh, and run_3b.sh to run them, respectively.
* You can adjust the max depth of the decision tree using variable *max_depth*

**Ensemble Learning**
***
**Correspondence**

* 2(a) -- BoostingTrees.py --result1.csv & result2.csv
* 2(b) -- baggedTrees.py --result3.csv
* 2(c) -- baggedTrees2c.py 
* 2(d) -- randomForest.py -- result4.csv
* 2(e) -- randomForest2e.py


**Linear Regression**
***
* You can run *LMS.py* for the **batch gradient descent algorithm** and **stochastic gradient descent algorithm**. 
* The variable *batch_r* and *batch_threshould* are used to set *r* and threshold of **batch gradient descent algorithm** respectively.
* The variable *stochastic_r* and *stochastic_threshould* are used to set *r* and threshold of **stochastic gradient descent algorithm** respectively.
* The results of 4(a) and 4(b) are stored in *4a.csv* and *4b.csv* under folder **Results**.


**Perceptron**
***
* You can run *standard_Perceptron.sh*, *voted_Perceptron.sh*, and *averaged_Perceptron.sh* for the **standard Perceptron**, **voted Perceptron**, and **averaged Perceptron**, respectively.
* The variable *T* and *r* are used to set epoch and step rate.


**SVM**
***

* You can run *sto_sub_gradient_SVM.sh* for the **Assignment 4 Practice 2**. 
* You can run *dual_SVM.sh* for the **Assignment 4 Practice 3**.


**Neural Networks**
* You can run *BP.sh* for the **Assignment 5 Practice 2(a)**. 
* You can run *NeuroNetwork.sh* for the **Assignment 5 Practice 2(b)**.
* You can run *NNZeros.sh* for the **Assignment 5 Practice 2(c)**.
* You can run *pytorchPy.sh* for the **Assignment 5 Practice 2(e)**.



